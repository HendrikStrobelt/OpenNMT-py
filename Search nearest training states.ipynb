{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "\n",
    "- load states.h5\n",
    "- Search nearest kNN with annoy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import annoy\n",
    "import h5py\n",
    "\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to build index etc (don't re-run!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 55, 500)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "f = h5py.File(\"states.h5\", \"r\")\n",
    "cstar = f[\"cstar\"]\n",
    "print(cstar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cstar to create a small copy\n",
    "small_copy = h5py.File(\"states_small.h5\", \"w\")\n",
    "small_copy.create_group('src')\n",
    "f.copy('src', small_copy['src'])\n",
    "small_copy.create_group('tgt')\n",
    "f.copy('tgt', small_copy['tgt'])\n",
    "small_copy.create_group('attn')\n",
    "f.copy('attn', small_copy['attn'])\n",
    "small_copy.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index\n",
    "t = AnnoyIndex(cstar.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add samples to index, takes long!\n",
    "for samplenum, sample in enumerate(cstar):\n",
    "    for tokennum, tokencontext in enumerate(sample):\n",
    "        index = cstar.shape[1] * samplenum + tokennum\n",
    "        t.add_item(index, tokencontext)\n",
    "#     if samplenum > 200:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build trees\n",
    "t.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save index to file\n",
    "t.save(\"states.ann\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the index from file\n",
    "u = AnnoyIndex(500)\n",
    "u.load(\"S2S/states.ann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file with states etc\n",
    "f = h5py.File(\"S2S/states_small.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loader for dictionary and load them\n",
    "def load_dict(fname):\n",
    "    ix2w = {}\n",
    "    with open(fname, \"r\") as f:\n",
    "        for l in f:\n",
    "            cline = l.split()\n",
    "            ix2w[int(cline[0])] = cline[1]\n",
    "    return ix2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dict = load_dict(\"S2S/src.dict\")\n",
    "tgt_dict = load_dict(\"S2S/tgt.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[210736, 534240, 232021, 306927, 112960]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test functionality by giving index as input\n",
    "def get_closest(ix, k=10):\n",
    "    return u.get_nns_by_item(ix,k)\n",
    "get_closest(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 46)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index is stretched out, need to find src/tgt index\n",
    "def convert_result_to_correct_index(oldix):\n",
    "    return oldix // 55, oldix % 55\n",
    "convert_result_to_correct_index(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform tokens, ignore padding (1)\n",
    "def ix2text(array, vocab, highlight=-1):\n",
    "    tokens = []\n",
    "    for ix, t in enumerate(array):\n",
    "        if ix == highlight:\n",
    "            tokens.append(\"___\" + vocab[t] + \"___\")\n",
    "        elif t != 1:\n",
    "            tokens.append(vocab[t])\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute length of a sentence when ignoring padding\n",
    "def compute_sent_length(array):\n",
    "    return np.sum([1 for t in array if t != 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is not acceptable that , with the help of the national bureaucracies , Parliament &apos;s legislative prerogative should be made null and void by means of implementing provisions whose content , purpose and extent are not laid down in advance .\n",
      "Es geht nicht an , dass über Ausführungsbestimmungen , deren Inhalt , Zweck ___und___ Ausmaß vorher nicht bestimmt ist , zusammen mit den nationalen Bürokratien das Gesetzgebungsrecht des Europäischen Parlaments ausgehebelt wird . </s>\n"
     ]
    }
   ],
   "source": [
    "# Convert a result for an index\n",
    "def convert_result(ix):\n",
    "    sentIx, tokIx = convert_result_to_correct_index(ix)\n",
    "    # Get raw list of tokens\n",
    "    src_in = f['src']['src'][sentIx]\n",
    "    tgt_in = f['tgt']['tgt'][sentIx][1:]\n",
    "    # Convert to text\n",
    "    src = ix2text(src_in, src_dict)\n",
    "    tgt = ix2text(tgt_in, tgt_dict, tokIx)\n",
    "    # Extract attention - currently does not work as expected :()\n",
    "    attn = f['attn']['attn'][sentIx]\n",
    "    src_len = compute_sent_length(src_in)\n",
    "    tgt_len = compute_sent_length(tgt_in)\n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    return src, tgt, attn\n",
    "_ = convert_result(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Case study - we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
